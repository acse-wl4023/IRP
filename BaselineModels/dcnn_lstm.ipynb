{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T02:59:25.427327Z",
     "start_time": "2024-06-19T02:58:44.003044Z"
    }
   },
   "outputs": [],
   "source": [
    "import Get_data as Gd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "directory = '..\\\\data\\\\Sibo_22Mar2024'\n",
    "folders = [os.path.join(directory, f, 'hessian_') for f in os.listdir(directory) if f.startswith('case_')]\n",
    "train_set, length = Gd.get_all_data(folders[:-2])\n",
    "# test_set, length_test = Gd.get_all_data(folders[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "preprocessor = Gd.PreprocessorCNN(train_set, 3)\n",
    "preprocessor.fit()\n",
    "\n",
    "tt = preprocessor.transform(train_set)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T03:01:46.513544Z",
     "start_time": "2024-06-19T02:59:25.463328Z"
    }
   },
   "id": "48cbaf89b4badada",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.03 GiB for an array with shape (2800, 97149) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m mm \u001B[38;5;241m=\u001B[39m preprocessor\u001B[38;5;241m.\u001B[39minverse_transform(tt)\n\u001B[0;32m      2\u001B[0m mm\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32m~\\source\\repos\\IRP\\BaselineModels\\Get_data.py:116\u001B[0m, in \u001B[0;36mPreprocessorCNN.inverse_transform\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    114\u001B[0m recon_data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros_like(x)\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_channel \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m--> 116\u001B[0m     recon_data[:, :, i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscalerList[i]\u001B[38;5;241m.\u001B[39minverse_transform(x[:, :, i])\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m recon_data\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1034\u001B[0m, in \u001B[0;36mStandardScaler.inverse_transform\u001B[1;34m(self, X, copy)\u001B[0m\n\u001B[0;32m   1031\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1033\u001B[0m copy \u001B[38;5;241m=\u001B[39m copy \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy\n\u001B[1;32m-> 1034\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1035\u001B[0m     X,\n\u001B[0;32m   1036\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1037\u001B[0m     copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m   1038\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mFLOAT_DTYPES,\n\u001B[0;32m   1039\u001B[0m     force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1040\u001B[0m )\n\u001B[0;32m   1042\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(X):\n\u001B[0;32m   1043\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwith_mean:\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\sklearn\\utils\\validation.py:950\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    947\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xp\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy.array_api\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m    948\u001B[0m     \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n\u001B[0;32m    949\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmay_share_memory(array, array_orig):\n\u001B[1;32m--> 950\u001B[0m         array \u001B[38;5;241m=\u001B[39m _asarray_with_order(\n\u001B[0;32m    951\u001B[0m             array, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, xp\u001B[38;5;241m=\u001B[39mxp\n\u001B[0;32m    952\u001B[0m         )\n\u001B[0;32m    953\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    954\u001B[0m     \u001B[38;5;66;03m# always make a copy for non-numpy arrays\u001B[39;00m\n\u001B[0;32m    955\u001B[0m     array \u001B[38;5;241m=\u001B[39m _asarray_with_order(\n\u001B[0;32m    956\u001B[0m         array, dtype\u001B[38;5;241m=\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, xp\u001B[38;5;241m=\u001B[39mxp\n\u001B[0;32m    957\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:186\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m xp\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumpy.array_api\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;66;03m# Use NumPy API to support order\u001B[39;00m\n\u001B[0;32m    185\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39masarray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    187\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    188\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:73\u001B[0m, in \u001B[0;36m_NumPyApiWrapper.asarray\u001B[1;34m(self, x, dtype, device, copy)\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21masarray\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;66;03m# Support copy in NumPy namespace\u001B[39;00m\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 73\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m numpy\u001B[38;5;241m.\u001B[39marray(x, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     75\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m numpy\u001B[38;5;241m.\u001B[39masarray(x, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 2.03 GiB for an array with shape (2800, 97149) and data type float64"
     ]
    }
   ],
   "source": [
    "mm = preprocessor.inverse_transform(tt)\n",
    "mm.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T03:02:31.666363Z",
     "start_time": "2024-06-19T03:01:46.551536Z"
    }
   },
   "id": "d6acb1bdfcd76c57",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "10.304402208942674"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T02:56:31.249240Z",
     "start_time": "2024-06-19T02:56:28.912607Z"
    }
   },
   "id": "acb60d7ceab2876a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Conv1DAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv1DAutoencoder, self).__init__()\n",
    "        \n",
    "        # 编码器部分\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # Output size: (97800 / 2) = 48900\n",
    "            \n",
    "            nn.Conv1d(in_channels=16, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # Output size: (97800 / 2) = 48900\n",
    "            \n",
    "            nn.Conv1d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),  # Output size: (97800 / 2) = 48900\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(1000, 100)\n",
    "        self.fc3 = nn.Linear(100, 1000)\n",
    "        self.fc4 = None\n",
    "        \n",
    "        # 解码器部分\n",
    "        # 解码器部分\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels=256, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 解压\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=64, out_channels=16, kernel_size=3, stride=2, padding=1, output_padding=1),  # 继续解压\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels=16, out_channels=3, kernel_size=3, stride=2, padding=1, output_padding=1),  # 继续解压\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        encoded_shape = x.shape\n",
    "        x = self.flatten(x)\n",
    "        num = x.shape[1]\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(num, 1000)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        if self.fc4 is None:\n",
    "            self.fc4 = nn.Linear(1000, num)\n",
    "        x = self.fc4(x)\n",
    "        x = x.view(encoded_shape)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T06:01:11.662231Z",
     "start_time": "2024-06-14T06:01:11.637883Z"
    }
   },
   "id": "254cb3f18e02c958",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, folders, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        test_datasets = []\n",
    "        total_loss = 0\n",
    "        for folder in folders:\n",
    "            files = [os.path.join(folder, f) for f in os.listdir(folder) if f.startswith('foward_soln_timestep_') and f.endswith('.npy')]\n",
    "            data = get_data(files)\n",
    "            train_set, test_set = create_dataset(data, 0.2)\n",
    "            test_datasets.append(test_set)\n",
    "            train_loader = DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "            loss_of_folder = 0\n",
    "            for input in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                output = model(input)\n",
    "                loss = criterion(input, output)  # 计算损失\n",
    "                loss.backward()\n",
    "                optimizer.step()  # 更新参数\n",
    "                loss_of_folder += loss.item()  # 累计损失\n",
    "            loss_of_folder = loss_of_folder / len(train_loader)\n",
    "            total_loss += loss_of_folder\n",
    "        # 在每个epoch后打印平均损失\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, train Loss: {total_loss / len(folders)}')\n",
    "        \n",
    "        #evaluate the model\n",
    "        recon_err = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for test_data in test_datasets:\n",
    "                scaler = TensorNormalizer()\n",
    "                scaler.fit(test_data)\n",
    "                transformed_data = scaler.transform(test_data)\n",
    "                err = 0\n",
    "                for i in range(transformed_data.shape[0]):\n",
    "                    output = model(transformed_data[i].unsqueeze(0))\n",
    "                    reconstruction = scaler.inverse_transform(output.squeeze())\n",
    "                    err += criterion(test_data[i], reconstruction).item()\n",
    "                recon_err += err/transformed_data.shape[0]\n",
    "            \n",
    "            recon_err = recon_err / len(test_datasets)\n",
    "            print(f'val Loss: {recon_err}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b68b7126b995d1c",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[98], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m Conv1DAutoencoder()\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters())\n\u001B[1;32m----> 6\u001B[0m train(model, optimizer, criterion, folders)\n",
      "Cell \u001B[1;32mIn[97], line 18\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, optimizer, criterion, folders, epochs)\u001B[0m\n\u001B[0;32m     16\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(\u001B[38;5;28minput\u001B[39m, output)  \u001B[38;5;66;03m# 计算损失\u001B[39;00m\n\u001B[0;32m     17\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 18\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()  \u001B[38;5;66;03m# 更新参数\u001B[39;00m\n\u001B[0;32m     19\u001B[0m     loss_of_folder \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()  \u001B[38;5;66;03m# 累计损失\u001B[39;00m\n\u001B[0;32m     20\u001B[0m loss_of_folder \u001B[38;5;241m=\u001B[39m loss_of_folder \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_loader)\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    383\u001B[0m             )\n\u001B[1;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    155\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    157\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[0;32m    158\u001B[0m         group,\n\u001B[0;32m    159\u001B[0m         params_with_grad,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    163\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    164\u001B[0m         state_steps)\n\u001B[1;32m--> 166\u001B[0m     adam(\n\u001B[0;32m    167\u001B[0m         params_with_grad,\n\u001B[0;32m    168\u001B[0m         grads,\n\u001B[0;32m    169\u001B[0m         exp_avgs,\n\u001B[0;32m    170\u001B[0m         exp_avg_sqs,\n\u001B[0;32m    171\u001B[0m         max_exp_avg_sqs,\n\u001B[0;32m    172\u001B[0m         state_steps,\n\u001B[0;32m    173\u001B[0m         amsgrad\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamsgrad\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    174\u001B[0m         has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    175\u001B[0m         beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    176\u001B[0m         beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    177\u001B[0m         lr\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    178\u001B[0m         weight_decay\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight_decay\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    179\u001B[0m         eps\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meps\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    180\u001B[0m         maximize\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    181\u001B[0m         foreach\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforeach\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    182\u001B[0m         capturable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    183\u001B[0m         differentiable\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    184\u001B[0m         fused\u001B[38;5;241m=\u001B[39mgroup[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfused\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m    185\u001B[0m         grad_scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrad_scale\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    186\u001B[0m         found_inf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[0;32m    187\u001B[0m     )\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    314\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[1;32m--> 316\u001B[0m func(params,\n\u001B[0;32m    317\u001B[0m      grads,\n\u001B[0;32m    318\u001B[0m      exp_avgs,\n\u001B[0;32m    319\u001B[0m      exp_avg_sqs,\n\u001B[0;32m    320\u001B[0m      max_exp_avg_sqs,\n\u001B[0;32m    321\u001B[0m      state_steps,\n\u001B[0;32m    322\u001B[0m      amsgrad\u001B[38;5;241m=\u001B[39mamsgrad,\n\u001B[0;32m    323\u001B[0m      has_complex\u001B[38;5;241m=\u001B[39mhas_complex,\n\u001B[0;32m    324\u001B[0m      beta1\u001B[38;5;241m=\u001B[39mbeta1,\n\u001B[0;32m    325\u001B[0m      beta2\u001B[38;5;241m=\u001B[39mbeta2,\n\u001B[0;32m    326\u001B[0m      lr\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m    327\u001B[0m      weight_decay\u001B[38;5;241m=\u001B[39mweight_decay,\n\u001B[0;32m    328\u001B[0m      eps\u001B[38;5;241m=\u001B[39meps,\n\u001B[0;32m    329\u001B[0m      maximize\u001B[38;5;241m=\u001B[39mmaximize,\n\u001B[0;32m    330\u001B[0m      capturable\u001B[38;5;241m=\u001B[39mcapturable,\n\u001B[0;32m    331\u001B[0m      differentiable\u001B[38;5;241m=\u001B[39mdifferentiable,\n\u001B[0;32m    332\u001B[0m      grad_scale\u001B[38;5;241m=\u001B[39mgrad_scale,\n\u001B[0;32m    333\u001B[0m      found_inf\u001B[38;5;241m=\u001B[39mfound_inf)\n",
      "File \u001B[1;32m~\\AppData\\Local\\miniconda3\\envs\\GNN\\Lib\\site-packages\\torch\\optim\\adam.py:382\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    380\u001B[0m     grad \u001B[38;5;241m=\u001B[39m grad\u001B[38;5;241m.\u001B[39madd(param, alpha\u001B[38;5;241m=\u001B[39mweight_decay)\n\u001B[1;32m--> 382\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_complex(param):\n\u001B[0;32m    383\u001B[0m     grad \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mview_as_real(grad)\n\u001B[0;32m    384\u001B[0m     exp_avg \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mview_as_real(exp_avg)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "model = Conv1DAutoencoder()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "train(model, optimizer, criterion, folders)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:11:43.938351Z",
     "start_time": "2024-06-14T08:54:49.868696Z"
    }
   },
   "id": "7656835ee1ea1232",
   "execution_count": 98
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
